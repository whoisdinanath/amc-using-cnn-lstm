{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../dataset/GOLD_XYZ_OSC_POSITIVE_COMBINED_NEW.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:05:35.814105Z",
     "iopub.status.busy": "2025-02-05T18:05:35.813821Z",
     "iopub.status.idle": "2025-02-05T18:05:42.898639Z",
     "shell.execute_reply": "2025-02-05T18:05:42.897962Z",
     "shell.execute_reply.started": "2025-02-05T18:05:35.814081Z"
    },
    "id": "ICcdsxvvP48q",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os, time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ray import tune\n",
    "from ray.train import Checkpoint, get_checkpoint, RunConfig\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray.cloudpickle as pickle\n",
    "from ray.tune import CLIReporter\n",
    "import ray\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:05:42.899693Z",
     "iopub.status.busy": "2025-02-05T18:05:42.899392Z",
     "iopub.status.idle": "2025-02-05T18:07:35.368730Z",
     "shell.execute_reply": "2025-02-05T18:07:35.367325Z",
     "shell.execute_reply.started": "2025-02-05T18:05:42.899665Z"
    },
    "id": "-UskgJOsP48s",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(dataset_path, 'r') as f:\n",
    "    X = f['X'][:]\n",
    "    Y = f['Y'][:]\n",
    "    Z = f['Z'][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:07:35.375810Z",
     "iopub.status.busy": "2025-02-05T18:07:35.375572Z",
     "iopub.status.idle": "2025-02-05T18:07:35.525255Z",
     "shell.execute_reply": "2025-02-05T18:07:35.524546Z",
     "shell.execute_reply.started": "2025-02-05T18:07:35.375781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epsilon = 1e-8  # A small value to avoid division by zero\n",
    "X_min = np.min(X, axis=1, keepdims=True)\n",
    "X_max = np.max(X, axis=1, keepdims=True)\n",
    "\n",
    "# Compute range\n",
    "X_range = X_max - X_min\n",
    "\n",
    "# Create a mask where range is 0\n",
    "mask = X_range == 0\n",
    "\n",
    "# Normalize to [-1, 1] (Avoid division by zero by adding epsilon)\n",
    "X = np.where(mask, 0, 2 * (X - X_min) / (X_range + epsilon) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:07:35.526358Z",
     "iopub.status.busy": "2025-02-05T18:07:35.526130Z",
     "iopub.status.idle": "2025-02-05T18:07:35.541265Z",
     "shell.execute_reply": "2025-02-05T18:07:35.540574Z",
     "shell.execute_reply.started": "2025-02-05T18:07:35.526340Z"
    },
    "id": "hkxQdbw5P48s",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "modulation_schemes = range(10)\n",
    "snr_levels = np.append(np.arange(0, 31, 2), 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot constellation diagrams for the extracted dataset\n",
    "def plot_constellation_snr_levels(modulation_class_index, extracted_classes, X, Y, Z):\n",
    "        # Get modulation class name from extracted_classes\n",
    "        class_name = extracted_classes[modulation_class_index]\n",
    "\n",
    "        # Find indices of the target modulation class\n",
    "        selected_class_indices = np.where(Y == modulation_class_index)[0]\n",
    "\n",
    "        # Get unique SNR levels\n",
    "        snr_values = np.unique(Z)\n",
    "\n",
    "        # Plot constellation diagrams for all SNR levels\n",
    "        plt.figure(figsize=(16, 20))\n",
    "        for i, snr in enumerate(snr_values):\n",
    "            # Find indices corresponding to the current SNR level\n",
    "            snr_indices = selected_class_indices[np.where(Z[selected_class_indices] == snr)[0]]\n",
    "\n",
    "            if len(snr_indices) == 0:\n",
    "                continue\n",
    "\n",
    "            # Extract the first sample for the current SNR level\n",
    "            iq_samples = X[snr_indices[0]]\n",
    "            # print(iq_samples.shape)\n",
    "            # break\n",
    "            # Separate into in-phase (I) and quadrature (Q) components\n",
    "            I = iq_samples[:, 0].flatten()\n",
    "            Q = iq_samples[:, 1].flatten()\n",
    "\n",
    "            # Plot the scatter plot\n",
    "            ax = plt.subplot(5, 4, i + 1)\n",
    "            ax.scatter(I, Q, s=5, alpha=0.8, color='black')\n",
    "            # ax.set_title(f\"SNR: {snr}dB\", fontsize=10, fontweight='bold')\n",
    "            plt.text(0.5, -0.1, f\"SNR: {int(snr)}dB\", fontsize=20, fontweight='bold', transform=ax.transAxes, ha='center', va='center')\n",
    "            # ax.axis('off')\n",
    "            ax.grid(True)\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.95)\n",
    "        # plt.savefig(f\"./visualization/constellation{classes[modulation_class_index]}.pdf\", format=\"pdf\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Paths to extracted dataset and relevant parameters\n",
    "classes = [\n",
    "    'BPSK', 'QPSK', '8PSK', '16QAM', '64QAM', 'AM-DSB-SC', 'AM-SSB-SC', 'FM', 'GMSK', 'GFSK'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modulation in range(10):\n",
    "    plot_constellation_snr_levels(modulation, classes, X, Y, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-05T18:07:35.542248Z",
     "iopub.status.busy": "2025-02-05T18:07:35.541926Z",
     "iopub.status.idle": "2025-02-05T18:07:35.884566Z",
     "shell.execute_reply": "2025-02-05T18:07:35.883810Z",
     "shell.execute_reply.started": "2025-02-05T18:07:35.542227Z"
    },
    "id": "F_vJ6zZ4P48t",
    "outputId": "07eacf90-d3b9-4c14-8fc5-7e9edcfb7245",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_size = 0.1\n",
    "valid_size = 0.1\n",
    "\n",
    "train_indices = []\n",
    "validation_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for modulation_scheme in modulation_schemes:\n",
    "    indices = np.where(Y == modulation_scheme)[0]\n",
    "    # now for these indices find each SNR indices in snr_levels\n",
    "    for snr in snr_levels:\n",
    "        snr_indices = np.where(Z[indices] == snr)[0]\n",
    "\n",
    "        # split into train+valid and test first\n",
    "        train_valid, test = train_test_split(\n",
    "            snr_indices, test_size=test_size, stratify=Z[indices][snr_indices], random_state=42\n",
    "        )\n",
    "\n",
    "        # further split train_valid into train and validation sets\n",
    "        train, valid = train_test_split(\n",
    "            train_valid, test_size=valid_size / (1 - test_size), stratify=Z[indices][train_valid], random_state=42\n",
    "        )\n",
    "\n",
    "        train_indices.extend(indices[train])\n",
    "        validation_indices.extend(indices[valid])\n",
    "        test_indices.extend(indices[test])\n",
    "\n",
    "# convert lists to numpy arrays for shuffling\n",
    "train_indices = np.array(train_indices)\n",
    "validation_indices = np.array(validation_indices)\n",
    "test_indices = np.array(test_indices)\n",
    "\n",
    "# shuffle the indices\n",
    "np.random.shuffle(train_indices)\n",
    "np.random.shuffle(validation_indices)\n",
    "np.random.shuffle(test_indices)\n",
    "\n",
    "\n",
    "print(\"Train size: \", len(train_indices))\n",
    "print(\"Validation size: \", len(validation_indices))\n",
    "print(\"Test size: \", len(test_indices))\n",
    "\n",
    "print(train_indices[:10])\n",
    "print(validation_indices[:10])\n",
    "print(test_indices[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:07:35.885525Z",
     "iopub.status.busy": "2025-02-05T18:07:35.885316Z",
     "iopub.status.idle": "2025-02-05T18:07:35.889637Z",
     "shell.execute_reply": "2025-02-05T18:07:35.888915Z",
     "shell.execute_reply.started": "2025-02-05T18:07:35.885507Z"
    },
    "id": "XkWwNeL4P48u",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def windowing_function(input_data):\n",
    "\n",
    "    if input_data.shape != (1024, 2):\n",
    "        raise ValueError(\"Input data must have shape (1024, 2).\")\n",
    "\n",
    "    window_size = 224\n",
    "    overlap = window_size // 2\n",
    "    step_size = window_size - overlap\n",
    "    output_sequences = []\n",
    "\n",
    "    for i in range(0, 1024 - window_size, step_size):\n",
    "        output_sequences.append(input_data[i:i + window_size])\n",
    "\n",
    "    return np.array(output_sequences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:07:35.890564Z",
     "iopub.status.busy": "2025-02-05T18:07:35.890352Z",
     "iopub.status.idle": "2025-02-05T18:07:45.412916Z",
     "shell.execute_reply": "2025-02-05T18:07:45.412105Z",
     "shell.execute_reply.started": "2025-02-05T18:07:35.890546Z"
    },
    "id": "73v_b-nQP48u",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_indices(indices):\n",
    "    X_seq = []\n",
    "    Y_seq = []\n",
    "\n",
    "    for idx in indices:\n",
    "        seq = windowing_function(X[idx])\n",
    "        X_seq.append(seq)\n",
    "        Y_seq.append(np.full(len(seq), Y[idx], dtype=np.float16))\n",
    "\n",
    "    return np.concatenate(X_seq, axis=0, dtype=np.float16), np.concatenate(Y_seq, axis=0)\n",
    "\n",
    "# Process training, validation, and test sets\n",
    "X_train, Y_train = process_indices(train_indices)\n",
    "X_valid, Y_valid = process_indices(validation_indices)\n",
    "X_test, Y_test = process_indices(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:07:45.414836Z",
     "iopub.status.busy": "2025-02-05T18:07:45.414592Z",
     "iopub.status.idle": "2025-02-05T18:07:46.110096Z",
     "shell.execute_reply": "2025-02-05T18:07:46.109288Z",
     "shell.execute_reply.started": "2025-02-05T18:07:45.414816Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "del X, Y, Z \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:07:46.111398Z",
     "iopub.status.busy": "2025-02-05T18:07:46.111067Z",
     "iopub.status.idle": "2025-02-05T18:07:46.124393Z",
     "shell.execute_reply": "2025-02-05T18:07:46.123601Z",
     "shell.execute_reply.started": "2025-02-05T18:07:46.111365Z"
    },
    "id": "WYbf1YwyP48v",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def amplitude_phase_seq_batch(iq_seq):\n",
    "    amplitude = np.sqrt(np.sum(np.square(iq_seq), axis=2, keepdims=True))\n",
    "    phase = np.arctan2(iq_seq[:, :, 1], iq_seq[:, :, 0])[..., np.newaxis]\n",
    "    return np.concatenate([iq_seq, amplitude, phase], axis=2)\n",
    "\n",
    "# def amplitude_phase_seq_batch(iq_seq):\n",
    "#     # Precompute squared values to avoid recalculating them\n",
    "#     squared = np.square(iq_seq)\n",
    "\n",
    "#     # Calculate amplitude and phase efficiently\n",
    "#     amplitude = np.sqrt(np.sum(squared, axis=2, keepdims=True))\n",
    "#     phase = np.arctan2(iq_seq[..., 1], iq_seq[..., 0])[..., np.newaxis]\n",
    "\n",
    "#     # Concatenate once instead of multiple times\n",
    "#     return np.concatenate((iq_seq, amplitude, phase), axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:07:46.125420Z",
     "iopub.status.busy": "2025-02-05T18:07:46.125224Z",
     "iopub.status.idle": "2025-02-05T18:07:46.134548Z",
     "shell.execute_reply": "2025-02-05T18:07:46.133926Z",
     "shell.execute_reply.started": "2025-02-05T18:07:46.125403Z"
    },
    "id": "eUkDdWGWP48w",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_preparation_alexnet(input_data, device):\n",
    "    iq_channel = input_data[:, :, :2] # Shape: (32, 224, 2)\n",
    "    amp_channel = input_data[:, :, 2:3]  # Shape: (32, 224, 1)\n",
    "    phase_channel = input_data[:, :, 3:]  # Shape: (32, 224, 1)\n",
    "\n",
    "    # print(iq_channel.shape)\n",
    "    iq_channel = iq_channel.repeat(1, 1, 112)\n",
    "    amp_channel = amp_channel.repeat(1, 1, 224)\n",
    "    phase_channel = phase_channel.repeat(1, 1, 224)\n",
    "\n",
    "    # adding new dimension for channel to make the shape (8, 3, 224, 224)\n",
    "    input_tensor = torch.stack([iq_channel, amp_channel, phase_channel], dim=1)\n",
    "\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    return input_tensor\n",
    "\n",
    "\n",
    "def data_preparation(initial_batch_data, device):\n",
    "    iq_channel = initial_batch_data[:, :, :2]  # Shape: (32, 224, 2)\n",
    "    amp_channel = initial_batch_data[:, :, 2:3]  # Shape: (32, 224, 1)\n",
    "    phase_channel = initial_batch_data[:, :, 3:]  # Shape: (32, 224, 1)\n",
    "\n",
    "    iq_channel = iq_channel.repeat(1, 1, 112)\n",
    "    amp_channel = amp_channel.repeat(1, 1, 224)\n",
    "    phase_channel = phase_channel.repeat(1, 1, 224)\n",
    "\n",
    "    input_tensor = torch.stack([iq_channel, amp_channel, phase_channel], dim=1)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:07:46.137050Z",
     "iopub.status.busy": "2025-02-05T18:07:46.136779Z",
     "iopub.status.idle": "2025-02-05T18:07:46.202335Z",
     "shell.execute_reply": "2025-02-05T18:07:46.201656Z",
     "shell.execute_reply.started": "2025-02-05T18:07:46.137001Z"
    },
    "id": "idjlx4WTP48w",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class AlexNetModified(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNetModified, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding = 0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.global_avg_pooling(x)\n",
    "        # x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # self.fc1 = nn.Linear(hidden_size * 8, 512)\n",
    "        # self.fc2 = nn.Linear(512, 256)\n",
    "        # self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=x.device).detach()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=x.device).detach()\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out.reshape(out.size(0), -1)  # Flatten all hidden states\n",
    "        # out = F.relu(self.fc1(out))\n",
    "        # out = F.relu(self.fc2(out))\n",
    "        # out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FullyConnectedLayer(nn.Module):\n",
    "    def __init__(self, input_size, l_1, l_2, drop_factor, output_size):\n",
    "        super(FullyConnectedLayer, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, l_1)\n",
    "        self.dropout1 = nn.Dropout(drop_factor)\n",
    "        self.l2 = nn.Linear(l_1, l_2)\n",
    "        self.dropout2 = nn.Dropout(drop_factor)\n",
    "        self.l3 = nn.Linear(l_2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.l1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.leaky_relu(self.l2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.l3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:37:34.218888Z",
     "iopub.status.busy": "2025-02-05T18:37:34.218503Z",
     "iopub.status.idle": "2025-02-05T18:37:34.223420Z",
     "shell.execute_reply": "2025-02-05T18:37:34.222529Z",
     "shell.execute_reply.started": "2025-02-05T18:37:34.218855Z"
    },
    "id": "LdMCT7T7P48x",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"input_size\": 256,\n",
    "    \"hidden_size\": 256,\n",
    "    \"num_layers\": 2,\n",
    "    \"num_classes\": 9,\n",
    "    \"num_epochs\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_seq\": 8,\n",
    "    \"log_interval\": 10,\n",
    "    \"l_1\": 512,\n",
    "    \"l_2\": 256,\n",
    "    \"drop_factor\": 0.5,\n",
    "    \"output_size\": 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:07:46.222556Z",
     "iopub.status.busy": "2025-02-05T18:07:46.222281Z",
     "iopub.status.idle": "2025-02-05T18:07:46.238859Z",
     "shell.execute_reply": "2025-02-05T18:07:46.238289Z",
     "shell.execute_reply.started": "2025-02-05T18:07:46.222536Z"
    },
    "id": "YWDKVNjwP48x",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataloader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size, num_seq, shuffle=True):\n",
    "        self.X = dataset.tensors[0]  # Input data\n",
    "        self.Y = dataset.tensors[1]  # Labels\n",
    "        self.batch_size = batch_size*num_seq\n",
    "        self.num_seq = num_seq\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.i >= len(self.X):\n",
    "            raise StopIteration\n",
    "\n",
    "        # Get indices for the batch\n",
    "        indices = self.indices[self.i:self.i + self.batch_size]\n",
    "        self.i += self.batch_size\n",
    "\n",
    "        batch_X = []\n",
    "        batch_Y = []\n",
    "\n",
    "        for index in indices:\n",
    "            seq = self.X[index]  # Get the sequence data\n",
    "            batch_X.append(seq)\n",
    "\n",
    "            # Only add corresponding labels for the sequences indexed by multiple of `num_seq`\n",
    "            if index % self.num_seq == 0:\n",
    "                batch_Y.append(self.Y[index])\n",
    "\n",
    "        # Stack the sequences into one tensor for X and Y\n",
    "        # Shape: [batch_size, seq_len, 224, 4]\n",
    "        batch_X_tensor = torch.stack(batch_X)\n",
    "        # Shape: [batch_size // num_seq, label_dim]\n",
    "        batch_Y_tensor = torch.stack(batch_Y)\n",
    "\n",
    "        # Move tensors to the correct device\n",
    "        return batch_X_tensor.to(device), batch_Y_tensor.to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T20:01:34.786678Z",
     "iopub.status.busy": "2025-02-05T20:01:34.786382Z",
     "iopub.status.idle": "2025-02-05T20:01:34.799266Z",
     "shell.execute_reply": "2025-02-05T20:01:34.798350Z",
     "shell.execute_reply.started": "2025-02-05T20:01:34.786658Z"
    },
    "id": "G65SGH-5P48x",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(config, train_dataloader, valid_dataloader,checkpoint_dir=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize models with tuned hyperparameters\n",
    "    ALEX_model = AlexNetModified().to(device)\n",
    "    LSTM_model = LSTMModel(\n",
    "        input_size=params['input_size'], hidden_size=params['hidden_size'], num_layers=2).to(device)\n",
    "    FC_model = FullyConnectedLayer(\n",
    "        input_size=params['hidden_size'] * params['num_seq'], l_1=config[\"l_1\"], l_2=config[\"l_2\"], drop_factor=config[\"drop_factor\"], output_size=params['output_size']\n",
    "    ).to(device)\n",
    "\n",
    "    # Define criterion and optimizer with the tuned learning rate\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        list(ALEX_model.parameters()) +\n",
    "        list(LSTM_model.parameters()) + list(FC_model.parameters()),\n",
    "        lr=config[\"learning_rate\"],\n",
    "    )\n",
    "\n",
    "    # Load checkpoint if available\n",
    "    if checkpoint_dir:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint.pt\")\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
    "            ALEX_model.load_state_dict(checkpoint[\"ALEX_model_state_dict\"])\n",
    "            LSTM_model.load_state_dict(checkpoint[\"LSTM_model_state_dict\"])\n",
    "            FC_model.load_state_dict(checkpoint[\"FC_model_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "            start_epoch = checkpoint[\"epoch\"]\n",
    "        else:\n",
    "            start_epoch = 0\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, params[\"num_epochs\"]):\n",
    "        ALEX_model.train()\n",
    "        LSTM_model.train()\n",
    "        FC_model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # print(inputs.shape)\n",
    "            alexnet_input = data_preparation_alexnet(inputs, device)\n",
    "            alexnet_input = alexnet_input.view(-1, 8, 3, 224, 224)\n",
    "            outputs_list = []\n",
    "\n",
    "            # Forward pass through AlexNet\n",
    "            for i in range(alexnet_input.shape[0]):\n",
    "                alexnet_output = ALEX_model(alexnet_input[i])\n",
    "                alexnet_output = alexnet_output.view(8, 256)\n",
    "                outputs_list.append(alexnet_output)\n",
    "\n",
    "            lstm_input = torch.stack(outputs_list)\n",
    "            lstm_output = LSTM_model(lstm_input)\n",
    "            fc_output = FC_model(lstm_output)\n",
    "\n",
    "            loss = criterion(fc_output, labels.long())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % params[\"log_interval\"] == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{params['num_epochs']}], Batch [{batch_idx}/{len(train_dataloader)}], Loss: {loss.item():.4f}\", flush=True)\n",
    "\n",
    "        # Average train loss for epoch\n",
    "        avg_train_loss = running_loss / len(train_dataloader)\n",
    "\n",
    "        # Validation phase\n",
    "        ALEX_model.eval()\n",
    "        LSTM_model.eval()\n",
    "        FC_model.eval()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in valid_dataloader:\n",
    "                val_inputs, val_labels = val_inputs.to(\n",
    "                    device), val_labels.to(device)\n",
    "                val_inputs = data_preparation_alexnet(val_inputs, device)\n",
    "                val_inputs = val_inputs.view(-1, 8, 3, 224, 224)\n",
    "                val_outputs_list = []\n",
    "\n",
    "                for i in range(val_inputs.shape[0]):\n",
    "                    alexnet_output = ALEX_model(val_inputs[i])\n",
    "                    alexnet_output = alexnet_output.view(8, 256)\n",
    "                    val_outputs_list.append(alexnet_output)\n",
    "\n",
    "                lstm_input = torch.stack(val_outputs_list)\n",
    "                lstm_output = LSTM_model(lstm_input)\n",
    "                fc_output = FC_model(lstm_output)\n",
    "\n",
    "                loss = criterion(fc_output, val_labels.long())\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(valid_dataloader)\n",
    "        print(f\"Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Checkpoint and log loss metrics\n",
    "        checkpoint_data = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"ALEX_model_state_dict\": ALEX_model.state_dict(),\n",
    "            \"LSTM_model_state_dict\": LSTM_model.state_dict(),\n",
    "            \"FC_model_state_dict\": FC_model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"val_loss\": avg_val_loss,\n",
    "        }\n",
    "\n",
    "        checkpoint_path = os.path.join(\"/kaggle/working/checkpoints/\", \"checkpoint.pt\")\n",
    "        torch.save(checkpoint_data, checkpoint_path)\n",
    "\n",
    "        ray.train.report(dict(val_loss=avg_val_loss, train_loss=avg_train_loss))\n",
    "        print(f\"Epoch [{epoch+1}/{params['num_epochs']}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:07:46.259954Z",
     "iopub.status.busy": "2025-02-05T18:07:46.259644Z",
     "iopub.status.idle": "2025-02-05T18:08:35.319234Z",
     "shell.execute_reply": "2025-02-05T18:08:35.318273Z",
     "shell.execute_reply.started": "2025-02-05T18:07:46.259926Z"
    },
    "id": "tWak2Sj7P48z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = amplitude_phase_seq_batch(X_train)\n",
    "X_valid = amplitude_phase_seq_batch(X_valid)\n",
    "X_test = amplitude_phase_seq_batch(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:08:35.320428Z",
     "iopub.status.busy": "2025-02-05T18:08:35.320134Z",
     "iopub.status.idle": "2025-02-05T18:08:39.792297Z",
     "shell.execute_reply": "2025-02-05T18:08:39.791399Z",
     "shell.execute_reply.started": "2025-02-05T18:08:35.320402Z"
    },
    "id": "_Z_BjG4HP48z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convert X_train, Y_train to tensor\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32).to(device)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float32).to(device)\n",
    "Y_valid = torch.tensor(Y_valid, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T18:08:39.793454Z",
     "iopub.status.busy": "2025-02-05T18:08:39.793139Z",
     "iopub.status.idle": "2025-02-05T18:08:39.800847Z",
     "shell.execute_reply": "2025-02-05T18:08:39.800062Z",
     "shell.execute_reply.started": "2025-02-05T18:08:39.793417Z"
    },
    "id": "KtIcrx-4P48z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_data = TensorDataset(X_train, Y_train)\n",
    "train_dataloader = CustomDataloader(train_data, batch_size=params[\"batch_size\"],shuffle=False, num_seq= params[\"num_seq\"])\n",
    "\n",
    "valid_data = TensorDataset(X_valid, Y_valid)\n",
    "valid_dataloader = CustomDataloader(valid_data, batch_size=params[\"batch_size\"], shuffle=False, num_seq=params[\"num_seq\"])\n",
    "\n",
    "\n",
    "test_data = TensorDataset(X_test, Y_test)\n",
    "test_dataloader = CustomDataloader(test_data, batch_size=params[\"batch_size\"], shuffle=False, num_seq=params[\"num_seq\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T19:21:06.060278Z",
     "iopub.status.busy": "2025-02-05T19:21:06.059939Z",
     "iopub.status.idle": "2025-02-05T19:21:06.065101Z",
     "shell.execute_reply": "2025-02-05T19:21:06.064162Z",
     "shell.execute_reply.started": "2025-02-05T19:21:06.060256Z"
    },
    "id": "DVU-wc_AP480",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the search space\n",
    "search_space = {\n",
    "    \"learning_rate\": tune.loguniform(5e-5, 3e-4),\n",
    "    \"drop_factor\": tune.grid_search([0.5, 0.6, 0.7]),\n",
    "    \"l_2\": tune.grid_search([256, 128]),\n",
    "    \"l_1\": tune.grid_search([512, 256])\n",
    "}\n",
    "\n",
    "# Define the ASHA scheduler\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"val_loss\", mode=\"min\", max_t=params[\"num_epochs\"], grace_period=1, reduction_factor=2\n",
    ")\n",
    "\n",
    "# Define the reporter\n",
    "reporter = CLIReporter(\n",
    "    metric_columns=[\"val_loss\", \"train_loss\", \"training_iteration\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-05T20:01:39.452485Z",
     "iopub.status.busy": "2025-02-05T20:01:39.452160Z",
     "iopub.status.idle": "2025-02-06T03:24:16.051318Z",
     "shell.execute_reply": "2025-02-06T03:24:16.049917Z",
     "shell.execute_reply.started": "2025-02-05T20:01:39.452457Z"
    },
    "id": "7DXVfvRzP480",
    "outputId": "28362747-f74d-4f75-c988-833031cd75e9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(\"ray_results\", exist_ok=True)\n",
    "\n",
    "# Run Ray Tune with defined search space\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(\n",
    "            train_model, train_dataloader=train_dataloader, valid_dataloader=valid_dataloader, checkpoint_dir=checkpoint_dir\n",
    "        ),\n",
    "        resources={\"cpu\": 4, \"gpu\": 1 if torch.cuda.is_available() else 0},\n",
    "    ),\n",
    "    param_space=search_space,\n",
    "    tune_config=tune.TuneConfig(scheduler=scheduler),\n",
    "    run_config=RunConfig(storage_path=\"./ray_results\")\n",
    ")\n",
    "\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T03:28:33.609211Z",
     "iopub.status.busy": "2025-02-06T03:28:33.608893Z",
     "iopub.status.idle": "2025-02-06T03:28:33.614044Z",
     "shell.execute_reply": "2025-02-06T03:28:33.613359Z",
     "shell.execute_reply.started": "2025-02-06T03:28:33.609184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters found were: \", results.get_best_result(\"val_loss\", mode=\"min\").config)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6584472,
     "sourceId": 10634865,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30841,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "amc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
